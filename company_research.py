import os
import json
import time
from typing import Dict
import pandas as pd
from openai import OpenAI
import streamlit as st
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Firecrawl ãƒªãƒ¢ãƒ¼ãƒˆMCPã‚µãƒ¼ãƒãƒ¼ã®è¨­å®š
FIRECRAWL_MCP_SERVER_URL = "http://localhost:8080"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã€ç’°å¢ƒå¤‰æ•°ã§ä¸Šæ›¸ãå¯èƒ½


class CompanyResearcher:
    def __init__(self, openai_api_key: str, firecrawl_server_url: str = None):
        self.client = OpenAI(api_key=openai_api_key)
        self.firecrawl_server_url = firecrawl_server_url or os.getenv(
            "FIRECRAWL_MCP_SERVER_URL", FIRECRAWL_MCP_SERVER_URL
        )

    def search_company_info(self, company_name: str, location: str = "") -> Dict:
        """
        Firecrawlãƒªãƒ¢ãƒ¼ãƒˆMCPã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨ã—ã¦ä¼æ¥­æƒ…å ±ã‚’æ¤œç´¢ãƒ»åé›†ã™ã‚‹
        """
        search_query = company_name
        if location:
            search_query += f" {location}"

        # Response APIã§ãƒªãƒ¢ãƒ¼ãƒˆMCPã‚µãƒ¼ãƒãƒ¼ã¨o3ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
        input_text = f"""
        ä»¥ä¸‹ã®ä¼æ¥­ã«ã¤ã„ã¦è©³ç´°ãªæƒ…å ±ã‚’WEBæ¤œç´¢ã§èª¿æŸ»ã—ã¦ãã ã•ã„ï¼š{search_query}

        ä»¥ä¸‹ã®é …ç›®ã«ã¤ã„ã¦å¯èƒ½ãªé™ã‚Šè©³ã—ãæƒ…å ±ã‚’æä¾›ã—ã¦ãã ã•ã„ï¼š
        1. æ­£å¼ãªä¼æ¥­åï¼ˆcorporation_nameï¼‰
        2. æ‰€åœ¨åœ°ãƒ»ä½æ‰€ï¼ˆaddressï¼‰
        3. ä»£è¡¨è€…åï¼ˆdaihyo_nameï¼‰
        4. ä¼æ¥­å…¬å¼ã‚µã‚¤ãƒˆURLï¼ˆcorporation_urlï¼‰
        5. ã‚µãƒ¼ãƒ“ã‚¹ãƒ»è£½å“ã‚µã‚¤ãƒˆURLï¼ˆservice_urlï¼‰
        6. å¾“æ¥­å“¡æ•°ï¼ˆemployee_sizeï¼‰
        7. è³‡æœ¬é‡‘ï¼ˆcapitalï¼‰
        8. è¨­ç«‹å¹´æœˆæ—¥ï¼ˆestablishedï¼‰
        9. ä¼æ¥­æ¦‚è¦ãƒ»äº‹æ¥­å†…å®¹ï¼ˆcorporate_overviewï¼‰
        10. å‚è€ƒURLï¼ˆsource_urlsï¼‰

        WEBæ¤œç´¢ã‚’æ´»ç”¨ã—ã¦æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã—ã€å›ç­”ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã§æä¾›ã—ã¦ãã ã•ã„ã€‚ä¸æ˜ãªé …ç›®ã¯"ä¸æ˜"ã¾ãŸã¯ç©ºæ–‡å­—åˆ—ã«ã—ã¦ãã ã•ã„ï¼š
        {{
            "corporation_name": "",
            "address": "",
            "daihyo_name": "",
            "corporation_url": "",
            "service_url": "",
            "employee_size": "",
            "capital": "",
            "established": "",
            "corporate_overview": "",
            "source_urls": ""
        }}
        """

        try:
            st.info(f"ğŸ” ä¼æ¥­æƒ…å ±æ¤œç´¢é–‹å§‹: {search_query}")

            # Response APIã§ãƒªãƒ¢ãƒ¼ãƒˆMCPã‚µãƒ¼ãƒãƒ¼ã¨o3ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            st.info("ğŸ¤– Response APIã§o3ãƒ¢ãƒ‡ãƒ« + ãƒªãƒ¢ãƒ¼ãƒˆMCPå®Ÿè¡Œä¸­...")
            response = self.client.responses.create(
                model="gpt-4o-mini",
                input=input_text,
                tools=[
                    {
                        "type": "mcp",
                        "server_label": "firecrawl",
                        "server_url": self.firecrawl_server_url,
                        "require_approval": "never",
                    }
                ],
            )

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰JSONéƒ¨åˆ†ã‚’æŠ½å‡º
            content = response.output_text
            st.success(f"âœ… {search_query} ã®æƒ…å ±å–å¾—å®Œäº†")

            # JSONã®é–‹å§‹ã¨çµ‚äº†ã‚’è¦‹ã¤ã‘ã‚‹
            json_start = content.find("{")
            json_end = content.rfind("}") + 1

            if json_start != -1 and json_end != -1:
                json_str = content[json_start:json_end]
                company_info = json.loads(json_str)

                # æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è¿½åŠ 
                company_info["search_query"] = search_query
                company_info["api_response_raw"] = content

                return company_info
            else:
                # JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                return {
                    "corporation_name": company_name,
                    "address": location,
                    "daihyo_name": "ä¸æ˜",
                    "corporation_url": "",
                    "service_url": "",
                    "employee_size": "ä¸æ˜",
                    "capital": "ä¸æ˜",
                    "established": "ä¸æ˜",
                    "corporate_overview": content,
                    "source_urls": "",
                    "search_query": search_query,
                    "api_response_raw": content,
                    "error": "JSONå½¢å¼ã®è§£æã«å¤±æ•—",
                }

        except json.JSONDecodeError as e:
            st.error(f"ğŸ“ JSONè§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                "corporation_name": company_name,
                "address": location,
                "daihyo_name": "ä¸æ˜",
                "corporation_url": "",
                "service_url": "",
                "employee_size": "ä¸æ˜",
                "capital": "ä¸æ˜",
                "established": "ä¸æ˜",
                "corporate_overview": "æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ",
                "source_urls": "",
                "search_query": search_query,
                "error": f"JSONè§£æã‚¨ãƒ©ãƒ¼: {str(e)}",
            }
        except Exception as e:
            st.error(f"ğŸš¨ APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                "corporation_name": company_name,
                "address": location,
                "daihyo_name": "ä¸æ˜",
                "corporation_url": "",
                "service_url": "",
                "employee_size": "ä¸æ˜",
                "capital": "ä¸æ˜",
                "established": "ä¸æ˜",
                "corporate_overview": "æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ",
                "source_urls": "",
                "search_query": search_query,
                "error": f"APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {str(e)}",
            }

    def research_companies_from_csv(
        self, df: pd.DataFrame, progress_callback=None
    ) -> pd.DataFrame:
        """
        CSVã‹ã‚‰ä¼æ¥­ä¸€è¦§ã‚’èª­ã¿è¾¼ã¿ã€å„ä¼æ¥­ã®æƒ…å ±ã‚’åé›†ã™ã‚‹
        """
        results = []
        total_companies = len(df)

        for index, row in df.iterrows():
            st.info(f"ğŸ“Š é€²æ—: {index + 1}/{total_companies} ä¼æ¥­ã‚’å‡¦ç†ä¸­...")

            if progress_callback:
                progress_callback(index + 1, total_companies)

            # CSVã‹ã‚‰ä¼æ¥­åã¨æ‰€åœ¨åœ°ã‚’å–å¾—
            company_name = ""
            location = ""

            # CSVã®åˆ—åã‚’æŸ”è»Ÿã«å¯¾å¿œ
            for col in df.columns:
                if any(
                    keyword in col.lower()
                    for keyword in ["name", "å", "ä¼æ¥­", "company", "corporation"]
                ):
                    company_name = str(row[col]) if pd.notna(row[col]) else ""
                elif any(
                    keyword in col.lower()
                    for keyword in ["address", "ä½æ‰€", "æ‰€åœ¨", "location"]
                ):
                    location = str(row[col]) if pd.notna(row[col]) else ""

            if not company_name:
                # æœ€åˆã®åˆ—ã‚’ä¼æ¥­åã¨ã—ã¦ä½¿ç”¨
                company_name = str(row.iloc[0]) if len(row) > 0 else ""

            if company_name:
                # ä¼æ¥­æƒ…å ±ã‚’åé›†
                company_info = self.search_company_info(company_name, location)
                results.append(company_info)

                # APIåˆ¶é™ã‚’è€ƒæ…®ã—ã¦å°‘ã—å¾…æ©Ÿ
                time.sleep(1)
            else:
                # ä¼æ¥­åãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                results.append(
                    {
                        "corporation_name": "ä¸æ˜",
                        "address": "",
                        "daihyo_name": "ä¸æ˜",
                        "corporation_url": "",
                        "service_url": "",
                        "employee_size": "ä¸æ˜",
                        "capital": "ä¸æ˜",
                        "established": "ä¸æ˜",
                        "corporate_overview": "ä¼æ¥­åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ",
                        "source_urls": "",
                        "search_query": "",
                        "error": "ä¼æ¥­åãŒè¦‹ã¤ã‹ã‚‰ãªã„",
                    }
                )

        return pd.DataFrame(results)


def get_openai_api_key():
    """
    OpenAI API KEYã‚’å–å¾—ã™ã‚‹ï¼ˆç’°å¢ƒå¤‰æ•°ã¾ãŸã¯Streamlitã®secretsï¼‰
    """
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
    api_key = os.getenv("OPENAI_API_KEY")

    # Streamlitã®secretsã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
    if not api_key and hasattr(st, "secrets"):
        try:
            api_key = st.secrets.get("OPENAI_API_KEY")
        except Exception:
            pass

    return api_key


def create_sample_csv():
    """
    ã‚µãƒ³ãƒ—ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹
    """
    sample_data = {
        "corporation_name": ["æ ªå¼ä¼šç¤¾ã‚µãƒ³ãƒ—ãƒ«", "ãƒ†ã‚¹ãƒˆæ ªå¼ä¼šç¤¾", "ä¾‹ç¤ºä¼æ¥­æ ªå¼ä¼šç¤¾"],
        "address": ["æ±äº¬éƒ½æ¸‹è°·åŒº", "å¤§é˜ªåºœå¤§é˜ªå¸‚", "ç¥å¥ˆå·çœŒæ¨ªæµœå¸‚"],
    }

    return pd.DataFrame(sample_data)
